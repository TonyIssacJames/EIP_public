{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/TonyIssacJames/EIP_public/blob/master/DNST_CIFAR10_AUG.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "K70hAckqg0EA",
    "outputId": "2fc6e1dd-b97c-46c9-9b74-1738093a5255"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# https://keras.io/\n",
    "#!pip install -q keras\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVIx_KIigxPV"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Concatenate\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNHw6luQg3gc"
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed to create session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cb2a26842bac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Create a session with the above options specified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m     \"\"\"\n\u001b[0;32m-> 1560\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1561\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed to create session."
     ]
    }
   ],
   "source": [
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dsO_yGxcg5D8"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "l = 15\n",
    "num_filter = 24\n",
    "compression = 0.7\n",
    "dropout_rate = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "mB7o3zu1g6eT",
    "outputId": "c1cea922-a38d-45da-f9d8-7977ab9c2dd2"
   },
   "outputs": [],
   "source": [
    "# Load CIFAR10 Data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
    "\n",
    "# convert to one hot encoing \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 32, 32, 3)\n",
      "(100000, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = np.append(x_train, x_train,axis=0)\n",
    "y_train = np.append(y_train, y_train,axis=0)\n",
    "print(x_train.shape)\n",
    "#print(np.append(x_train, x_train,axis=0).shape)\n",
    "#print(np.append(y_train, y_train,axis=0).shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "from scipy.misc import toimage\n",
    "def show_imgs(X):\n",
    "    pyplot.figure(1)\n",
    "    k = 0\n",
    "    for i in range(0,4):\n",
    "        for j in range(0,4):\n",
    "            pyplot.subplot2grid((4,4),(i,j))\n",
    "            pyplot.imshow(toimage(X[k]))\n",
    "            k = k+1\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "\n",
    "show_imgs(x_test[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=40,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,    # randomly flip images\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Callback for saving the best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath= \"weights_tr_05_v2_lr.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ee-sge5Kg7vr"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def add_denseblock(input, num_filter = 24, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l):\n",
    "        BatchNorm = BatchNormalization()(temp)\n",
    "        relu = Activation('relu')(BatchNorm)\n",
    "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
    "        if dropout_rate>0:\n",
    "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOP6IPsGhBwb"
   },
   "outputs": [],
   "source": [
    "def add_transition(input, num_filter = 24, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0RaKFpubhDIC"
   },
   "outputs": [],
   "source": [
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = Flatten()(AvgPooling)\n",
    "    output = Dense(num_classes, activation='softmax')(flat)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anPCpQWhhGb7"
   },
   "outputs": [],
   "source": [
    "#num_filter = 16\n",
    "#Sdropout_rate = 0.2\n",
    "#l = 12\n",
    "input = Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "Fourth_Block = add_denseblock(Third_Transition, num_filter, dropout_rate)\n",
    "Fourth_Transition = add_transition(Fourth_Block, num_filter, dropout_rate)\n",
    "\n",
    "#Fifth_Block = add_denseblock(Fourth_Transition, num_filter, dropout_rate)\n",
    "#Fifth_Transition = add_transition(Fifth_Block, num_filter, dropout_rate)\n",
    "\n",
    "Last_Block = add_denseblock(Fourth_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer(Last_Block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 9860
    },
    "colab_type": "code",
    "id": "1kFh7pdxhNtT",
    "outputId": "160abc05-9e09-4454-d453-0e33a7d95796"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-68343b4b165f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Model' is not defined"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4XOsW3ahSkL"
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data so reloading will be easy\n",
    "#np.save(\"x_train\", x_train)\n",
    "#np.save(\"y_train\", y_train)\n",
    "#np.save(\"x_test\", x_test)\n",
    "#np.save(\"y_test\", y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1771
    },
    "colab_type": "code",
    "id": "crhGk7kEhXAz",
    "outputId": "e3e2d0d0-1492-41ab-df5b-5a7ecd705c2c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 764s 977ms/step - loss: 1.6354 - acc: 0.3932 - val_loss: 1.9286 - val_acc: 0.4274\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.42740, saving model to weights_tr_05_v2.best.hdf5\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 671s 858ms/step - loss: 1.2677 - acc: 0.5436 - val_loss: 2.4901 - val_acc: 0.4513\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.42740 to 0.45130, saving model to weights_tr_05_v2.best.hdf5\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 671s 858ms/step - loss: 0.9840 - acc: 0.6521 - val_loss: 1.0411 - val_acc: 0.6595\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.56930 to 0.65950, saving model to weights_tr_05_v2.best.hdf5\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 670s 856ms/step - loss: 0.9076 - acc: 0.6830 - val_loss: 1.7530 - val_acc: 0.5659\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.65950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fadc45f8358>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list)'''\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                    batch_size=batch_size),\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('weights_tr_05_v2_epoch_2.hdf5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data so reloading will be easy\n",
    "#np.save(\"x_train\", x_train)\n",
    "#np.save(\"y_train\", y_train)\n",
    "#np.save(\"x_test\", x_test)\n",
    "#np.save(\"y_test\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 668s 854ms/step - loss: 0.8411 - acc: 0.7075 - val_loss: 0.9860 - val_acc: 0.7146\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.65950 to 0.71460, saving model to weights_tr_05_v2.best.hdf5\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 671s 858ms/step - loss: 0.7908 - acc: 0.7256 - val_loss: 1.5897 - val_acc: 0.5887\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.71460\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 672s 859ms/step - loss: 0.7488 - acc: 0.7417 - val_loss: 1.0648 - val_acc: 0.6928\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.71460\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 668s 855ms/step - loss: 0.7123 - acc: 0.7544 - val_loss: 0.9650 - val_acc: 0.7041\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.71460\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 667s 853ms/step - loss: 0.6820 - acc: 0.7659 - val_loss: 0.7442 - val_acc: 0.7739\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.71460 to 0.77390, saving model to weights_tr_05_v2.best.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac6a1a9470>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list)'''\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                    batch_size=batch_size),\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('weights_tr_05_v2_epoch_10.hdf5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data so reloading will be easy\n",
    "#np.save(\"x_train\", x_train)\n",
    "#np.save(\"y_train\", y_train)\n",
    "#np.save(\"x_test\", x_test)\n",
    "#np.save(\"y_test\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 672s 859ms/step - loss: 0.6521 - acc: 0.7763 - val_loss: 0.8179 - val_acc: 0.7610\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.77390\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 671s 859ms/step - loss: 0.6295 - acc: 0.7833 - val_loss: 0.8100 - val_acc: 0.7533\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.77390\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 672s 859ms/step - loss: 0.6029 - acc: 0.7932 - val_loss: 0.8990 - val_acc: 0.7452\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.77390\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 672s 859ms/step - loss: 0.5842 - acc: 0.7987 - val_loss: 0.8529 - val_acc: 0.7665\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.77390\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 671s 858ms/step - loss: 0.5647 - acc: 0.8047 - val_loss: 0.7705 - val_acc: 0.7722\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.77390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7facf5985048>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list)'''\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                    batch_size=batch_size),\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('weights_tr_05_v2_epoch_15.hdf5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 671s 858ms/step - loss: 0.5484 - acc: 0.8109 - val_loss: 0.7213 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.77390 to 0.79420, saving model to weights_tr_05_v2.best.hdf5\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 671s 858ms/step - loss: 0.5333 - acc: 0.8172 - val_loss: 0.6789 - val_acc: 0.8038\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.79420 to 0.80380, saving model to weights_tr_05_v2.best.hdf5\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 671s 858ms/step - loss: 0.5172 - acc: 0.8214 - val_loss: 0.7315 - val_acc: 0.7902\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.80380\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 846s 1s/step - loss: 0.5077 - acc: 0.8251 - val_loss: 0.7059 - val_acc: 0.7973\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.80380\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 1217s 2s/step - loss: 0.4963 - acc: 0.8289 - val_loss: 0.7094 - val_acc: 0.8016\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.80380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac6a1a9390>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list)'''\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                    batch_size=batch_size),\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('weights_tr_05_v2_epoch_20.hdf5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ZcWydmIVhZGr",
    "outputId": "a0345aa5-79ff-4e56-eb94-50437b43c4fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 18s 2ms/step\n",
      "Test loss: 0.5077479893147946\n",
      "Test accuracy: 0.8528\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 1234s 2s/step - loss: 0.4872 - acc: 0.8324 - val_loss: 0.7691 - val_acc: 0.7863\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.80380\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 1235s 2s/step - loss: 0.4744 - acc: 0.8374 - val_loss: 0.8123 - val_acc: 0.7831\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.80380\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 1237s 2s/step - loss: 0.4653 - acc: 0.8391 - val_loss: 0.6871 - val_acc: 0.8062\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.80380 to 0.80620, saving model to weights_tr_05_v2.best.hdf5\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 1235s 2s/step - loss: 0.4590 - acc: 0.8421 - val_loss: 0.8698 - val_acc: 0.7767\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.80620\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 1236s 2s/step - loss: 0.4491 - acc: 0.8462 - val_loss: 0.7899 - val_acc: 0.7944\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.80620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac6a1a9780>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list)'''\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                    batch_size=batch_size),\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('weights_tr_05_v2_epoch_25.hdf5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#continue from here on the prviously saved model after 25 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Callback for Cyclic LR\n",
    "#from clr_callback import *\n",
    "#clr = CyclicLR(base_lr=0.0001, max_lr=0.006, step_size=2000., mode='triangular2')\n",
    "#callbacks_list = [checkpoint, clr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 43s 4ms/step\n",
      "Test loss: 0.7898893457889556\n",
      "Test accuracy: 0.7944\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('weights_tr_05_v2_epoch_25.hdf5')\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 383s 490ms/step - loss: 0.4390 - acc: 0.8489 - val_loss: 0.6460 - val_acc: 0.8196\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.81960, saving model to weights_tr_05_v2.best.hdf5\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 364s 465ms/step - loss: 0.4308 - acc: 0.8511 - val_loss: 0.8679 - val_acc: 0.7722\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.81960\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 251s 321ms/step - loss: 0.4233 - acc: 0.8542 - val_loss: 0.5758 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.81960 to 0.83350, saving model to weights_tr_05_v2.best.hdf5\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 181s 231ms/step - loss: 0.4153 - acc: 0.8561 - val_loss: 0.6232 - val_acc: 0.8196\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.83350\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 183s 234ms/step - loss: 0.4100 - acc: 0.8580 - val_loss: 0.6012 - val_acc: 0.8279\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.83350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2f7cda12e8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list)'''\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                    batch_size=batch_size),\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('weights_tr_05_v2_01_epoch_30.hdf5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 181s 232ms/step - loss: 0.4032 - acc: 0.8613 - val_loss: 0.8183 - val_acc: 0.7862\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.83350\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 181s 232ms/step - loss: 0.3992 - acc: 0.8616 - val_loss: 0.4627 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.83350 to 0.85800, saving model to weights_tr_05_v2.best.hdf5\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 181s 232ms/step - loss: 0.3928 - acc: 0.8650 - val_loss: 0.5665 - val_acc: 0.8408\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.85800\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 183s 234ms/step - loss: 0.3878 - acc: 0.8667 - val_loss: 0.5736 - val_acc: 0.8409\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.85800\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 181s 232ms/step - loss: 0.3810 - acc: 0.8674 - val_loss: 0.5771 - val_acc: 0.8405\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.85800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2f694f0e48>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list)'''\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                    batch_size=batch_size),\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('weights_tr_05_v2_01_epoch_35.hdf5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 181s 232ms/step - loss: 0.3725 - acc: 0.8713 - val_loss: 0.5250 - val_acc: 0.8460\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85800\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 181s 232ms/step - loss: 0.3718 - acc: 0.8723 - val_loss: 0.5498 - val_acc: 0.8434\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.85800\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 181s 232ms/step - loss: 0.3642 - acc: 0.8733 - val_loss: 0.4524 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.85800 to 0.86600, saving model to weights_tr_05_v2.best.hdf5\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 182s 233ms/step - loss: 0.3629 - acc: 0.8746 - val_loss: 0.4293 - val_acc: 0.8760\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.86600 to 0.87600, saving model to weights_tr_05_v2.best.hdf5\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 183s 235ms/step - loss: 0.3592 - acc: 0.8757 - val_loss: 0.4635 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.87600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2f69450a58>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list)'''\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                    batch_size=batch_size),\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('weights_tr_05_v2_01_epoch_40.hdf5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 185s 236ms/step - loss: 0.3555 - acc: 0.8768 - val_loss: 0.5389 - val_acc: 0.8429\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.87600\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 183s 235ms/step - loss: 0.3500 - acc: 0.8782 - val_loss: 0.4083 - val_acc: 0.8794\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.87600 to 0.87940, saving model to weights_tr_05_v2.best.hdf5\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 181s 232ms/step - loss: 0.3479 - acc: 0.8801 - val_loss: 0.5198 - val_acc: 0.8556\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.87940\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 182s 233ms/step - loss: 0.3411 - acc: 0.8829 - val_loss: 0.6450 - val_acc: 0.8343\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.87940\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 183s 235ms/step - loss: 0.3374 - acc: 0.8833 - val_loss: 0.6072 - val_acc: 0.8423\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.87940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2f7cdac048>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list)'''\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                    batch_size=batch_size),\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('weights_tr_05_v2_01_epoch_45.hdf5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 183s 235ms/step - loss: 0.3367 - acc: 0.8831 - val_loss: 0.3829 - val_acc: 0.8876\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.87940 to 0.88760, saving model to weights_tr_05_v2.best.hdf5\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 183s 233ms/step - loss: 0.3306 - acc: 0.8846 - val_loss: 0.5001 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.88760\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 182s 233ms/step - loss: 0.3308 - acc: 0.8855 - val_loss: 0.5275 - val_acc: 0.8555\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.88760\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 181s 231ms/step - loss: 0.3246 - acc: 0.8857 - val_loss: 0.6510 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.88760\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 181s 232ms/step - loss: 0.3216 - acc: 0.8885 - val_loss: 0.5107 - val_acc: 0.8556\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.88760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2f694fc208>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list)'''\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                    batch_size=batch_size),\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UE3lF6EH1r_L",
    "outputId": "92df862c-76a7-4a02-9533-6c164bc5984d"
   },
   "outputs": [],
   "source": [
    "model.save('weights_tr_05_v2_01_epoch_50.hdf5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 14s 1ms/step\n",
      "Test loss: 0.38292595955729486\n",
      "Test accuracy: 0.8876\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "new_model = load_model(\"weights_tr_05_v2.best.hdf5\")\n",
    "score = new_model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ai-yZ2ED5AK1"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "\n",
    "#files.download('DNST_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Og56VCRh5j8V"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "DNST_CIFAR10_AUG.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
